---
title: "Stat 443 Project"
output:
  pdf_document: default
  html_document: default
header-includes:
- \usepackage{color}
- \usepackage{graphicx}
- \usepackage{epic}
- \usepackage{hyperref}
- \PassOptionsToPackage{pdfmark}{hyperref}\RequirePackage{hyperref}
- \newcommand{\ve}[1]{\mathbf{#1}}
- \newcommand{\pop}[1]{\mathcal{#1}}
- \newcommand{\samp}[1]{\mathcal{#1}}
- \newcommand{\subspace}[1]{\mathcal{#1}}
- \newcommand{\sv}[1]{\boldsymbol{#1}}
- \newcommand{\sm}[1]{\boldsymbol{#1}}
- \newcommand{\tr}[1]{{#1}^{\mkern-1.5mu\mathsf{T}}}
- \newcommand{\abs}[1]{\left\lvert ~{#1} ~\right\rvert}
- \newcommand{\size}[1]{\left\lvert {#1} \right\rvert}
- \newcommand{\norm}[1]{\left|\left|{#1}\right|\right|}
- \newcommand{\field}[1]{\mathbb{#1}}
- \newcommand{\Reals}{\field{R}}
- \newcommand{\Integers}{\field{Z}}
- \newcommand{\Naturals}{\field{N}}
- \newcommand{\Complex}{\field{C}}
- \newcommand{\Rationals}{\field{Q}}
- \newcommand{\widebar}[1]{\overline{#1}}
- \newcommand{\wig}[1]{\tilde{#1}}
- \newcommand{\bigwig}[1]{\widetilde{#1}}
- \newcommand{\leftgiven}{~\left\lvert~}
- \newcommand{\given}{~\vert~}
- \newcommand{\indep}{\bot\hspace{-.6em}\bot}
- \newcommand{\notindep}{\bot\hspace{-.6em}\bot\hspace{-0.75em}/\hspace{.4em}}
- \newcommand{\depend}{\Join}
- \newcommand{\notdepend}{\Join\hspace{-0.9 em}/\hspace{.4em}}
- \newcommand{\imply}{\Longrightarrow}
- \newcommand{\notimply}{\Longrightarrow \hspace{-1.5em}/ \hspace{0.8em}}
- \newcommand*{\intersect}{\cap}
- \newcommand*{\union}{\cup}
- \newcommand{\suchthat}{~:~}
- \newcommand{\st}{~:~}
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r directories, echo = FALSE, warning = FALSE, message = FALSE}
library(knitr)
library(astsa)
library(forecast)
library(ggplot2)
library(gridExtra)
library(tidyverse)
library(forecast)
library(tidyr)
library(urca)
library(dplyr)
library(fGarch) # for GARCH model
library(rugarch)
library(tseries)
library(MTS)
library(quantmod)
library(mgarchBEKK)
library(rugarch)
library(rmgarch) # Vec-Garch, CCC-Garch, DCC-Garch
library(PerformanceAnalytics) # For computing VaR
library(stats) # For imputation
library(KFAS)
```


**Scenario 1**

Number of pages for text + R Output (excluding plots + code): 1.75 pages

```{r, warning = FALSE, message = FALSE, include = FALSE}
hydro_data <- read.csv("hydrology_data.txt", header = TRUE)
hydro_data <- ts(hydro_data)
```

We first start by plotting our hydrology data.

```{r, warning = FALSE, message = FALSE, echo = FALSE}
plot(hydro_data, col = "blue", main = 'Hydrology Time Series')
```


We will first diagnose stationarity by plotting the ACF/PACF plots of the original data with residual diagnostics:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
par(mfrow=c(2,2))
acf(hydro_data, main='ACF of Data')
pacf(hydro_data, main='PACF of Data')

# Fit a trend and residuals
fit <- tslm(hydro_data ~ trend)
resids <- resid(fit)
qqnorm(resids, main = "Normal Q-Q Plot")
qqline(resids)

# Residuals vs. Fitted plot
plot(as.numeric(fitted(fit)), as.numeric(residuals(fit)), type ="p",
     main = "Residuals vs Fitted", xlab = "Fitted", ylab = "Residuals")
```

The ACF pattern is an oscillation with a downward trend, which implies that the time series has some kind of seasonal pattern. This is clearly not stationary. The PACF cuts off at $p=1$ The residuals vs fitted plot appears to also indicate this sinusodial pattern. So we will try using a SARIMA model with parameter $p=1$.

To confirm stationary, we also use the Augmented Dickey-Fuller (ADF) test and KPSS test to check for stationarity.

```{r, warning = FALSE, message = FALSE, echo = FALSE}
adf.test(hydro_data)
summary(ur.kpss(hydro_data))
```

By the KPSS test for stationary, for the original data, our KPSS value of 1.3229 exceeds all cutoffs that reject stationary. This is also supported by the ADF test having p-value > 0.05.

Because we want to achieve stationarity, we will to determine the difference parameters (for seasonal and non-seasonal components). To do so, we can continuously difference them (separately) until we achieve an ADF p-value of < 0.05.

The final output with residuals diagnostics is displayed below:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
# Non-seasonal differencing
d <- 0
diff_data <- hydro_data
while(adf.test(diff_data)$p.value > 0.05) {
  diff_data <- diff(diff_data)
  d <- d + 1
}
checkresiduals(diff(diff_data))

# Seasonal differencing
D <- 0
seasonal_diff_data <- hydro_data
while(adf.test(seasonal_diff_data)$p.value > 0.05) {
  seasonal_diff_data <- diff(seasonal_diff_data, lag = 12)
  D <- D + 1
}
checkresiduals(diff(seasonal_diff_data))
```

```{r, warning = FALSE, message = FALSE, echo = FALSE}
# Display the number of differencing steps
cat("Non-seasonal differencing (d):", d, "\n")
cat("Seasonal differencing (D):", D, "\n")
```

It looks like the best values for the differences is $d=1$ for non-seasonal difference and $D=1$ for seasonal difference

Confirming this with our residual diagnostics, both ACF's appear to have lost the sinusodial property and now somewhat appears stationary:

- The residuals appear random in both plots
- The ACF's only have spikes at the seasonal lags at 12
- The residual bell-curves are both symmetrically normal.

Now we want to find the best AR and MA parameters. To do this, we identify the ACF and PACF plots of both non-seasonal and seasonal models.

```{r, warning = FALSE, message = FALSE, echo = FALSE}
par(mfrow=c(2,2))
acf(diff_data, main='ACF First Non-Seasonal Difference')
pacf(diff_data, main='PACF First Non-Seasonal Difference')
acf(seasonal_diff_data, main='ACF First Seasonal Difference')
pacf(seasonal_diff_data, main='PACF First Seasonal Difference')
```

For the non-seasonal difference model, the ACF still appears to draw a sinusodial pattern (so perhaps no $q$ value), whereas the PACF cutsoff looks a bit unclear, so it is worth exploring different $p$ values.

For the seasonal difference model, the ACF is slowly decreasing (it is worth exploring $q=0$ and $q=1$) and the PACF has a cutoff at $p=1$, along with spikes at the seasonalities every 12 lags.

So we want to test out a few SARIMA models with what we have learned:


\newpage
First we try out the SARIMA(1,1,0,1,1,0) model, by using the ARIMA function in R:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
fit1a <- arima(hydro_data, order=c(1,1,0), seasonal=list(order=c(1,1,0), period=12))
tsdiag(fit1a)
```

\newpage
Then try out the SARIMA(3,1,0,1,1,0) model:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
fit1b <- arima(hydro_data, order=c(3,1,0), seasonal=list(order=c(1,1,0), period=12))
tsdiag(fit1b)
```

\newpage
Then we try out the SARIMA(3,1,0,1,1,1) model:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
fit1c <- arima(hydro_data, order=c(3,1,0), seasonal=list(order=c(1,1,1), period=12))
tsdiag(fit1c)
```

\newpage
Then we try out the SARIMA(5,1,0,1,1,1) model:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
fit1d <- arima(hydro_data, order=c(5,1,1), seasonal=list(order=c(1,1,1), period=12))
tsdiag(fit1d)
```

All the standardized residuals appear to be random, all the ACF values appear to be stationary (no real spikes outside), and the p-values are above the line for the Ljung-Box statistic, then all of these models are decent.

To find the best model, we pick the model with the lowest AIC/BIC value:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
aic_1a <- AIC(fit1a)
bic_1a <- BIC(fit1a)

aic_1b <- AIC(fit1b)
bic_1b <- BIC(fit1b)

aic_1c <- AIC(fit1c)
bic_1c <- BIC(fit1c)

aic_1d <- AIC(fit1d)
bic_1d <- BIC(fit1d)

mse_table <- data.frame(
  Model = c("SARIMA(1,1,0,1,1,0)", "SARIMA(3,1,0,1,1,0)", 
            "SARIMA(3,1,0,1,1,1)","SARIMA(5,1,0,1,1,1)"),
    AIC = c(aic_1a,aic_1b,aic_1c,aic_1d),
    BIC = c(bic_1a,bic_1b,bic_1c,bic_1d)
)

# Print the table
kable(mse_table, col.names = c("Model", "AIC", "BIC"), 
      caption = "AIC and BIC of Different Models")
```


With the lowest AIC/BIC values, the best model is the SARIMA(3,1,0,1,1,1) model!

Forecasting our model for the next 24 months:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
forecast_length <- 24
forecast_result <- forecast(fit1c, h = forecast_length)

plot(forecast_result, main = "Forecast of Hydrology Data",
     xlab = "Month", ylab = "Resolution", col.lab = "blue")
```

For the next 24-month ahead forecasts, this looks like a reasonable forecast for our hydrology data (the blue line). The 95% prediction intervals is indicated by the light-shaded grey area around the forecast, whereas the 80% prediction intervals are the dark grey shaded area.

The 95% prediction intervals indicate that if we forecast even further, the intervals get wider. They do not look too wide for a 24-month forecast so this forecast overall looks good.

```{r, warning = FALSE, message = FALSE, include = FALSE}
# Write the txt file
last.name <- "Miranda"
student.id <- "20818719"

forecast1 <- forecast_result$mean  # Forecast is a vector length 24 for forecast 1
write(forecast1, file = paste("Scenario1_",last.name,student.id,".txt", sep = ""), ncolumns = 1)
```



\newpage


**Scenario 2**

Number of pages for text + R Output (excluding plots + code): 2

We first create a function to read all 40 stock text files using a loop and storing it within a data frame.

```{r, warning = FALSE, message = FALSE, include = FALSE}
stock_files <- paste0("stock", 1:40, ".txt")

# Function for reading files in
load_data <- function(file_path) {
  data <- read.csv(file_path, header = TRUE)
  return(data)
}

# Read the files in, assuming comma separator
txt_files_df <- lapply(stock_files, function(file_path) {read.csv(file_path, header = TRUE)})
stock_data <- as.data.frame(txt_files_df)

n <- nrow(stock_data)
n_fit <- n-10
```


Then we fit different kinds of GARCH models for each set of stock.

We first want to test 3 models: GARCH(1,1), Exponential GARCH(1,1) (eGARCH) and Gjr-GARCH(1,1). 

- The GARCH model describes the most basic time series model where variance changes over time, which is useful for modelling volatility in stocks. 
- The eGARCH is designed to handle asymmetries in volatility, and it can capture leverage effects where negative reutrns might have a different impact on volatility compared to positive returns. 
- GJR-GARCH incorporates an additional term to the variance formula to account for the asymmetry in volatility (similar to eGARCH with different approach)

We test these models individually for each stock, which means that we run $3 \times 40 = 120$ tests in total.

```{r, warning = FALSE, message = FALSE, include = FALSE}
# Define different GARCH specifications
garch <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)), mean.model = list(armaOrder = c(0, 0)), distribution.model = "norm")
egarch <- ugarchspec(variance.model = list(model = "eGARCH", garchOrder = c(1, 1)), mean.model = list(armaOrder = c(0, 0)), distribution.model = "norm")
gjrgarch <- ugarchspec(variance.model = list(model = "gjrGARCH", garchOrder = c(1, 1)), mean.model = list(armaOrder = c(0, 0)), distribution.model = "norm")
```

We find out which model is best by comparing the AIC Values of each of the 3 models for each stock and take the lowest one. We decide to store the index of the best model within a vector called "decision". The first index refers to GARCH, the second index refers to eGARCH, and the third index refers to GJR-GARCH.

```{r, warning = FALSE, message = FALSE}
# Add decision vector to decide which model best fits the stock
decision <- c()

for (i in 1:40){
  AIC <- c()
  single_stock <- stock_data[i]
  
  garch_model <- ugarchfit(garch, single_stock)
  egarch_model <- ugarchfit(egarch, single_stock)
  gjrgarch_model <- ugarchfit(gjrgarch, single_stock)
  
  AIC[1] <- infocriteria(garch_model)[1,]
  AIC[2] <- infocriteria(egarch_model)[1,]
  AIC[3] <- infocriteria(gjrgarch_model)[1,]
  
  # Find the index of the smallest AIC Value:
  decision[i] = which.min(AIC)
}
```

An example of this is presented below with Stock 40, having the lowest AIC value for the eGARCH model, therefore storing 2 as the last element of the decision vector.

```{r, warning = FALSE, message = FALSE, echo = FALSE}
# Example with stock 40
aic_outputs <- data.frame(
  Model = c("GARCH(1,1)", "EGARCH(1,1)", "GJR-GARCH(1,1)"),
    AIC = c(AIC[1],AIC[2],AIC[3])
)

# Print the table
kable(aic_outputs, col.names = c("Model", "AIC"),
      caption = "AIC of different models for Stock 40")
```

We can output the decision indices and the counts of them below, where the index for each decision pertains to the stock number. For example, the 11th decision is the decision for which is the best model for the 11th stock, being the GARCH model (with value 1)

```{r, warning = FALSE, message = FALSE, echo = FALSE}
decision
table(decision)
```

Note that most of the models have the best model of eGARCH among the three predominantly, followed by the GJR-GARCH.

The reason why we only use (1,1) as parameters because we discussed in class how the best models do not provide a significantly better forecast than the GARCH(1,1) model. This result was established by the tests of for superior predictive ability of White (2000) and Hensen (2001).

We then fit the best models for each stock (using the decision vector to match each stock to their best models) and find the value at risk levels for each stock.

```{r, warning = FALSE, message = FALSE, include = FALSE}
garch_models <- mapply(function(returns, choice) {
  if (choice == 1) {spec <- garch} 
  else if (choice == 2) {spec <- egarch} 
  else {spec <- gjrgarch}
  
  ugarchfit(spec, data = returns)
}, returns = stock_data, choice = decision, SIMPLIFY = FALSE)

# Define the quantile (VaR level)
p <- 0.15
n_ahead <- 10

VaR_forecasts <- lapply(garch_models, function(model) {
  # Forecast 10 steps ahead
  forecast <- ugarchforecast(model, n.ahead = n_ahead)
  
  # Extract forecasted sigma (volatility) and mean
  sigma_forecast <- sigma(forecast)
  mean_forecast <- fitted(forecast)
  
  # Calculate the VaR for each step ahead
  VaR <- mean_forecast + qnorm(p) * sigma_forecast
  return(VaR)
})

# Display the VaR forecasts
# VaR_forecasts
```


We also want to confirm the residual diagnostics for these stocks using these models. We present it for the first two stocks since that is what we will be presenting for our forecast plot. The same process can be achieved for the other 38 stocks.

```{r, warning = FALSE, message = FALSE, echo = FALSE}
stock1 <- stock_data[1:150,1]
stock2 <- stock_data[1:150,2]

# Residual analysis
garch1 <- ugarchfit(gjrgarch, data = stock1)
garch2 <- ugarchfit(gjrgarch, data = stock2)

stock1_residuals <- residuals(garch1) # follows GJR-Garch
stock2_residuals <- residuals(garch2) # Follows GJR-Garch

# Plot residuals
plot(stock1_residuals, ylab = "Stock 1 Residuals", main = "Stock 1 Residuals")
acf(stock1_residuals, main = "ACF of Residuals of Stock 1")

plot(stock2_residuals, ylab = "Stock 2 Residuals", main = "Stock 2 Residuals")
acf(stock2_residuals, main = "ACF of Residuals of Stock 2")

# Perform the portmanteau test on the residuals
box_test_stock1 <- Box.test(stock1_residuals, type = "Ljung-Box")
box_test_stock2 <- Box.test(stock2_residuals, type = "Ljung-Box")

cat("Ljung-Box test for Stock 1's residuals:\n")
print(box_test_stock1)
cat("Ljung-Box test for Stock 2's residuals:\n")
print(box_test_stock2)
```

- Goodness of fit from residuals:
  - Both the residuals from both models look very similar and appear to be randomly/evenly spread out (cloudy pattern)
  - Both ACF's look very similar and appear to be stationary (no major spikes outside interval)
  - This supports the Box-Ljung test for the residuals where our p-values are greater than 0.05

We can now plot the forecast for the first two stocks:

```{r, warning = FALSE, message = FALSE, include = FALSE}
# Append forecasts to our data
stock1_combined <- append(stock1,VaR_forecasts[[1]][1:10])
stock2_combined <- append(stock2,VaR_forecasts[[2]][1:10])
```

```{r, warning = FALSE, message = FALSE, echo = FALSE}
ggplot(mapping=aes(x=1:160)) +
  geom_line(aes(y=stock1_combined,col='Stock 1 Forecast')) +
  geom_line(aes(y=stock2_combined,col='Stock 2 Forecast')) +
  xlab("Time") +
  ylab("Values") +
  ggtitle("Stocks 1 and 2 Forecast") +
  theme_bw() +
  theme(legend.title = element_blank())
```



Looking at the forecasts for the first two stocks, the first stock appears to have a decent forecast that captures the volatility of the stock returns well and appears to have low risk value for the stock. Therefore, this stock appears to be safe to invest into.

For Stock 2, the forecast of the Value-At-Risk is super volatile and unpredictable. So the Value-At-Risk is unstable for the first 10 steps ahead for second stock. Therefore, this stock is not safe to invest into.

The same can be performed with all other stocks.


```{r, warning = FALSE, message = FALSE, include = FALSE}
# Write it in the txt file
# Make matrix for all the forecasts
results <- matrix(ncol = 1, nrow = 10)
for (i in 1:40) {
  results <- cbind(results, VaR_forecasts[[i]][1:10])
}
results <- results[,-1]
```

```{r, warning = FALSE, message = FALSE, include = FALSE}
last.name <- "Miranda" # replace with your last name
student.id <- "20818719"  #replace with your student id
###
# Scenario 2
###
forecast2 <- results

write.table(forecast2, file = paste("Scenario2_",last.name,student.id,".txt", sep = ""), sep ="," , col.names = F, row.names = F) 
```


\newpage

**Scenario 3**

Number of pages for text + R Output (excluding plots + code): 1.5 pages

To start, because we have imputed data, we want to use Kalman Filtering and Smoothing to determine the missing values for the beer. We can accomplish this by using the other files on car, steel, gas, electricity, and temperature.

We first combine them into one data frame.

```{r, warning = FALSE, message = FALSE, include = FALSE}
library(zoo)
# Load the datasets
beer <- read.csv("beer.txt", header = TRUE)
car <- read.csv("car.txt", header = TRUE)
steel <- read.csv("steel.txt", header = TRUE)
gas <- read.csv("gas.txt", header = TRUE)
electricity <- read.csv("electricity.txt", header = TRUE)
temperature <- read.csv("temperature.txt", header = TRUE)

# Convert year and month in temperature to a date
temperature$Date <- paste(temperature$Year, sprintf("%02d", temperature$Month), sep = "-")
temperature <- subset(temperature, select = -c(Year, Month))
temperature <- temperature[,c("Date", "Value")]

# Merge datasets by Date (inner join to get common dates)
data <- merge(beer, car, by = "Date", all = TRUE)
data <- merge(data, steel, by = "Date", all = TRUE)
data <- merge(data, gas, by = "Date", all = TRUE)
data <- merge(data, electricity, by = "Date", all = TRUE)
data <- merge(data, temperature, by = "Date", all = TRUE)

# Rename columns for convenience
colnames(data) <- c("Date", "beer", "car", "steel", "gas", "electricity", "temperature")
data <- subset(data, Date >= "1956-01")
data <- subset(data, Date <= "1992-03")

# Check for NA values and interpolate missing values in the exogenous variables
data$car <- zoo::na.approx(data$car, na.rm = FALSE)
data$steel <- zoo::na.approx(data$steel, na.rm = FALSE)
data$gas <- zoo::na.approx(data$gas, na.rm = FALSE)
data$electricity <- zoo::na.approx(data$electricity, na.rm = FALSE)
data$temperature <- zoo::na.approx(data$temperature, na.rm = FALSE)

# Fill in missing dates and interpolate missing values in the exogenous variables
data_zoo <- zoo(data[, -1], order.by = data$Date)
```

Note that we only used data starting from January 1956 since temperature had an earlier start date of November 1943 (hard to estimate given that no other file has any data).

I tried to fit a Kalman Filtering and Smoothing Model, but the imputed values ended up to be very different from our original data (in the negatives). This is show in the plot next page. After trying different model parameters (including interactions and different relationships), I proceeded to try a different method.

```{r, warning = FALSE, message = FALSE, include = FALSE}
# Define the state-space model
model <- SSModel(beer ~ car + steel + gas + electricity + temperature, H = NA, data = data_zoo)

# Fit the model using the Kalman Filter
fit <- fitSSM(model, inits = rep(0, 6))

# Extract the fitted model
fitted_model <- fit$model
```

```{r, warning = FALSE, message = FALSE, include = FALSE}
library(KFAS)
# Apply Kalman Filtering and smoothing
kf_result <- KFS(fitted_model, filtering = "state", smoothing = "none")
```

When I tried doing Kalman Filtering, Smoothing, and both, the result ended up having the same parameters.

```{r, warning = FALSE, message = FALSE, include = FALSE}
data_beer_kf <- data$beer

# Impute the missing values in the beer series
data_beer_kf[is.na(data_beer_kf)] <- kf_result$a[is.na(beer$Value)]
```

```{r, warning = FALSE, message = FALSE, echo = FALSE}
ts_beer <- ts(beer$Value, start = c(1956,1), end = c(1992,3), frequency = 12)
ts_kf <- ts(data_beer_kf, start = c(1956,1), end = c(1992,3), frequency = 12)

# Plot the original and filled beer data
plot(ts_beer, type="l", col="lightblue", lty=1, 
     ylab="Beer Production", xlab="Time", 
     main="Beer Production with Missing Values Filled", lwd = 1.5)
lines(ts_kf, col="red", lty = 2)

# Add legend
legend("topleft", legend=c("Original Beer Data", "Kalman Filter/Smoothing"),
       col=c("lightblue", "red"), lty=c(1, 2))
```

Even the simplest model with just the intercept value of 1 didn't seem to work very well:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
# Simplified model
model_simple <- SSModel(beer ~ 1, H = NA, data = data_zoo)
fit_simple <- fitSSM(model_simple, inits = rep(1, 1))
smoothed_simple <- KFS(fit_simple$model, smoothing = "state")

data_smoothed <- data$beer
data_smoothed[is.na(data_smoothed)] <- smoothed_simple$a[is.na(beer$Value)]

# Check results
plot(ts(beer$Value, start = c(1956,1), end = c(1992,3), frequency = 12), 
     type = "l", col = "lightblue", ylab = "Smoothed Beer Data", 
     xlab = "Date", main = "Simplest Model")
lines(ts(data_smoothed, start = c(1956,1), end = c(1992,3), frequency = 12), col = "red")
legend("topleft", legend = c("Smoothed Beer Data", "Original Beer Data"), 
       col = c("lightblue", "red"), lty = 1)
```

Alternatively, we can also try using the ARIMAX model, since it is excellent at handling missing values by using exogenous variables that are from other time series. We can use normal time series techniques like ACF the most optimal model in this scenario. We also scaled the exogenous variables since they are of different scales.

```{r, warning = FALSE, message = FALSE, include = FALSE}
data <- subset(data, Date >= "1956-01")
data <- subset(data, Date <= "1992-03")

# Extract the variables
beer_ts <- ts(data$beer, start = c(1956,1), end = c(1992,3), frequency=12)  # Assuming monthly data
exog <- as.matrix(data[, c("car", "steel", "gas", "electricity", "temperature")])

exogenous_vars_scaled <- scale(exog)
```

We can't really see the ACF or the stationarity tests since there are missing data in our beer data.

So we just go ahead and try to fit the best models. We start with the auto.arima model recommended by R:

```{r, warning = FALSE, message = FALSE, include = FALSE}
# Compare with auto.arima
model_auto <- auto.arima(beer_ts, seasonal = TRUE, xreg=exogenous_vars_scaled)
```

The default model appears to be the SARIMA(1,1,0,2,0,0) model.

```{r, warning = FALSE, message = FALSE, echo = FALSE}
# Evaluate model performance
checkresiduals(model_auto)
```

Note that our ACF values imply that there is some seasonality since they lag peaks occur every 12 values. We try to incorporate this into a SARIMAX model.

I proceeded to test multiple kinds of models, by first resolving differencing by looking at the residual ACF plot and adjusted parameters based on the spikes or patterns presented.

In the end, I decided to go with three SARIMAX models:

- SARIMA(2,1,2,2,1,2)
- SARIMA(3,1,2,2,1,2)
- SARIMA(2,1,3,2,1,1)

```{r, warning = FALSE, message = FALSE, include = FALSE}
model_212 <- arima(beer_ts, order=c(2,1,2), seasonal=list(order=c(2,1,2), period=12), xreg=exogenous_vars_scaled)
model_312 <- arima(beer_ts, order=c(3,1,2), seasonal=list(order=c(2,1,2), period=12), xreg=exogenous_vars_scaled)
model_213 <- arima(beer_ts, order=c(2,1,3), seasonal=list(order=c(2,1,1), period=12), xreg=exogenous_vars_scaled)
```

We can now compute and compare AIC values to find the best ARIMAX model:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
aic_auto <- AIC(model_auto)
aic_212 <- AIC(model_212)
aic_312 <- AIC(model_312)
aic_213 <- AIC(model_213)

aic_table2 <- data.frame(
  Model = c("Auto.Arima", "SARIMA(2,1,2,2,1,2)", 
            "SARIMA(3,1,2,2,1,2)","SARIMA(2,1,3,2,1,1)"),
    AIC = c(aic_auto,aic_212,aic_312,aic_213)
)

# Print the table
kable(aic_table2, col.names = c("Model", "AIC"), 
      caption = "AIC of Different Models")
```

So our best model is the SARIMA(2,1,3,2,1,1) model!

Evaluating the residuals:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
# Evaluate model performance
checkresiduals(model_213)
```

The ACF plot looks pretty stationary since all the spikes are basically within the line. The residuals look fairly random and normally distributed. Therefore, this model looks appropriate for our beer dataset.

We can now compute the predicted values of the imputed values:

```{r, warning = FALSE, message = FALSE, include = FALSE}
predicted_beer <- beer_ts
best_model <- model_213
```

```{r, warning = FALSE, message = FALSE, include = FALSE}
# Assume `beer_ts` is your time series and `sarimax_model` is your fitted SARIMAX model
# Identify missing indices in `beer_ts`
missing_indices <- which(is.na(beer_ts))

# Create a matrix of exogenous variables for the missing periods
exogenous_vars_missing <- exogenous_vars_scaled[missing_indices, , drop = FALSE]

# Forecast the missing values with 95% prediction intervals
forecast_result <- predict(best_model, n.ahead = length(missing_indices), newxreg = exogenous_vars_missing, se.fit = TRUE)

# Extract the predicted values, standard errors, and calculate prediction intervals
predicted_values <- forecast_result$pred
se <- forecast_result$se

# Calculate the 95% prediction intervals
lower_bound <- predicted_values - 1.96 * se
upper_bound <- predicted_values + 1.96 * se

# Replace missing values in the beer series with the forecasted values
predicted_beer[missing_indices] <- predicted_values
```

```{r, warning = FALSE, message = FALSE, echo = FALSE}
# Plot the original and filled beer data
plot(beer_ts, type="l", col="red", lty=1, ylab="Beer Production", xlab="Date", main="Beer Production with Missing Values Filled")
points(predicted_beer, col="purple", type = "l", lty = 2)
polygon(c(time(beer_ts)[missing_indices], rev(time(beer_ts)[missing_indices])),
        c(upper_bound, rev(lower_bound)), col = rgb(0, 1, 0, alpha = 0.3), border = NA)

# Add legend
legend("topleft", legend = c("Observed Data", "Forecasted Values", "95% Prediction Interval"),
       col = c("red", "purple", rgb(0, 1, 0, alpha = 0.3)), lty = c(1, 1, NA), 
       lwd = c(1, 2, NA), pch = c(NA, NA, 15), fill = c(NA, NA, rgb(0, 1, 0, alpha = 0.3)))
```

From the plot, the forecast of the imputed values seem to make sense with small prediction intervals as well. So we can conclude scencario 3.

```{r, warning = FALSE, message = FALSE, include = FALSE}
last.name <- "Miranda" # replace with your last name
student.id <- "20818719"  #replace with your student id
###
# Scenario 3 
###
imputation3 <- as.vector(predicted_values) # Imputation of length 30

write(imputation3, file = paste("Scenario3_",last.name,student.id,".txt", sep = ""), ncolumns = 1)
```


\newpage

**Scenario 4**

Number of pages for text + R Output (excluding plots + code): 1.5 pages

Using our imputed data from Scenario 3, we can now refit our data to forecast the 24 steps ahead. We will be re-fitting our models assuming our imputed data is the true value.

Note that we will not be using any exogenous variables for this scenario since none of the other txt files provide any values after the date for the beer data.

We start with looking at our ACF plot and residual diagnostics.

```{r, warning = FALSE, message = FALSE, echo = FALSE}
# Evaluate model performance
checkresiduals(predicted_beer)
```

Our ACF plot is clearly not stationary, and indicates a strong indication of seasonality every 12 months. The residuals also indicate an upward oscillatory pattern which suggests that more work needs to be done to make our data stationary.

We first try with the auto.arima model again. It appears that it is the SARIMA(0,0,3,0,1,2) with drift.

```{r, warning = FALSE, message = FALSE, include = FALSE}
# Compare with auto.arima
model_auto2 <- auto.arima(predicted_beer, seasonal = TRUE)
```

```{r, warning = FALSE, message = FALSE, echo = FALSE}
# Evaluate model performance
checkresiduals(model_auto2)
```

The ACF plot still indicate minor seasonality levels with peaks every 12 lags.

We first try our previous models from Scenario 3 to test if our best model is the same as the one for the imputed values.

```{r, warning = FALSE, message = FALSE, include = FALSE}
model2_212 <- arima(predicted_beer, order=c(2,1,2), seasonal=list(order=c(2,1,2), period=12))
model2_312 <- arima(predicted_beer, order=c(3,1,2), seasonal=list(order=c(2,1,2), period=12))
model2_213 <- arima(predicted_beer, order=c(2,1,3), seasonal=list(order=c(2,1,1), period=12))
```

```{r, warning = FALSE, message = FALSE, echo = FALSE}
aic2_auto <- AIC(model_auto2)
aic2_212 <- AIC(model2_212)
aic2_312 <- AIC(model2_312)
aic2_213 <- AIC(model2_213)

aic_table3 <- data.frame(
  Model = c("Auto.Arima", "SARIMA(2,1,2,2,1,2)", 
            "SARIMA(3,1,2,2,1,2)","SARIMA(2,1,3,2,1,1)"),
    AIC = c(aic2_auto,aic2_212,aic2_312,aic2_213)
)

# Print the table
kable(aic_table3, col.names = c("Model", "AIC"), 
      caption = "AIC of Different Models")
```

This time, our best model is the SARIMA(3,1,2,2,1,2) model! It barely beat the initial model in Scenario 3

Evaluating the residuals:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
# Evaluate model performance
checkresiduals(model2_312)
```

The residual ACF plot doesn't look too bad, with only a few spikes outside the interval. In addition, our residual plots appear normal and random. Therefore, this models looks appropriate for our data.

```{r, warning = FALSE, message = FALSE, include = FALSE}
# Forecast the next 24 steps ahead with 95% prediction intervals
forecast_result2 <- predict(model2_312, n.ahead=24, se.fit=TRUE)

# Extract forecasted values and standard errors
forecasted_values2 <- forecast_result2$pred
se2 <- forecast_result2$se

# Calculate the 95% prediction intervals
lower_bound2 <- forecasted_values2 - 1.96 * se2
upper_bound2 <- forecasted_values2 + 1.96 * se2
```

Now we plot our forecast for 24 steps ahead:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
extended_ts <- ts(forecasted_values2, start = c(1992,3), end = c(1994,3), frequency = 12)
extended_dates <- seq(from=max(time(beer_ts))+0.083, by=0.083, length.out=24)

# Plot the original and filled beer data
plot(predicted_beer, type="l", col="red", lty=1, ylab="Beer Production", xlab="Date", main="Beer Production Forecast with 95% Prediction Intervals")
lines(extended_ts, col="purple", lty=1, lwd=1)
polygon(c(extended_dates, rev(extended_dates)),
        c(upper_bound2, rev(lower_bound2)), col = rgb(0, 1, 0, alpha = 0.3), border = NA)

# Add legend
legend("topleft", legend = c("Observed Data", "Forecasted Values", "95% Prediction Interval"),
       col = c("red", "purple", rgb(0, 1, 0, alpha = 0.3)), lty = c(1, 1, NA), 
       lwd = c(1, 2, NA), pch = c(NA, NA, 15), fill = c(NA, NA, rgb(0, 1, 0, alpha = 0.3)))
```

The forecast for 24 steps ahead seems to make sense and the confidence interval doesn't seem too large. Therefore, this seems to be an appropriate model for our new beer dataset.

```{r, warning = FALSE, message = FALSE, include = FALSE}
last.name <- "Miranda" # replace with your last name
student.id <- "20818719"  #replace with your student id
###
# Scenario 4
###
forecast4 <- as.vector(forecasted_values2) # Forecast of length 24

write(forecast4, file = paste("Scenario4_",last.name,student.id,".txt", sep = ""), ncolumns = 1 )
```

\newpage

**Scenario 5**

Number of pages for text + R Output (excluding plots + code): 1.75 pages

```{r, warning = FALSE, message = FALSE, include = FALSE}
data_city1 <- read.csv("pollutionCity1.txt", header = TRUE)
data_city2 <- read.csv("pollutionCity2.txt", header = TRUE)
data_city3 <- read.csv("pollutionCity3.txt", header = TRUE)

ts_city1 <- ts(data_city1$Value, frequency = 48) # 48 half-hour periods per day
ts_city2 <- ts(data_city2$Value, frequency = 48)
ts_city3 <- ts(data_city3$Value, frequency = 48)
```

We first start by plotting our three series.

```{r, warning = FALSE, message = FALSE, echo = FALSE}
plot(ts_city1, col = "blue", main = 'City 1 Pollution')
plot(ts_city2, col = "blue", main = 'City 2 Pollution')
plot(ts_city3, col = "blue", main = 'City 3 Pollution')
```

We will first diagnose stationarity by plotting the ACF/PACF plots of the original data with residual diagnostics:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
par(mfrow=c(2,2))
acf(ts_city1, main='ACF of City 1')
pacf(ts_city1, main='PACF of City 1')

# Fit a trend and residuals
fit <- tslm(ts_city1 ~ trend)
resids <- resid(fit)
qqnorm(resids, main = "Normal Q-Q Plot")
qqline(resids)

# Residuals vs. Fitted plot
plot(as.numeric(fitted(fit)), as.numeric(residuals(fit)), type ="p",
     main = "Residuals vs Fitted", xlab = "Fitted", ylab = "Residuals")
```

```{r, warning = FALSE, message = FALSE, echo = FALSE}
par(mfrow=c(2,2))
acf(ts_city2, main='ACF of City 2')
pacf(ts_city2, main='PACF of City 2')

# Fit a trend and residuals
fit <- tslm(ts_city2 ~ trend)
resids <- resid(fit)
qqnorm(resids, main = "Normal Q-Q Plot")
qqline(resids)

# Residuals vs. Fitted plot
plot(as.numeric(fitted(fit)), as.numeric(residuals(fit)), type ="p",
     main = "Residuals vs Fitted", xlab = "Fitted", ylab = "Residuals")
```

```{r, warning = FALSE, message = FALSE, echo = FALSE}
par(mfrow=c(2,2))
acf(ts_city3, main='ACF of City 3')
pacf(ts_city3, main='PACF of City 3')

# Fit a trend and residuals
fit <- tslm(ts_city3 ~ trend)
resids <- resid(fit)
qqnorm(resids, main = "Normal Q-Q Plot")
qqline(resids)

# Residuals vs. Fitted plot
plot(as.numeric(fitted(fit)), as.numeric(residuals(fit)), type ="p",
     main = "Residuals vs Fitted", xlab = "Fitted", ylab = "Residuals")
```
 
For all the ACF's for the 3 cities, they are clearly not stationary because there is no clear cutoff and a steady decrease in the spikes of the ACF. All the PACF's also look like they exceed the cutoff periodically. All the normal QQ-plots violate normality since the QQ-points are off the QQ-line and the residuals vs fitted plot all indicate a somewhat oscillatory pattern.
 
We first take the first differences of the time series and plot their ACF's and PACF's.
 
```{r, warning = FALSE, message = FALSE, echo = FALSE} 
par(mfrow=c(2,3))
acf(diff(ts_city1), main='ACF of Diff City 1')
acf(diff(ts_city2), main='ACF of Diff City 2')
acf(diff(ts_city3), main='ACF of Diff City 3')
pacf(diff(ts_city1), main='PACF of Diff City 1')
pacf(diff(ts_city2), main='PACF of Diff City 2')
pacf(diff(ts_city3), main='PACF of Diff City 3')
```

For City 1, our ACF cuts off at $q=1$ with mild spikes every other 0.2 lags (maybe seasonality). While investigating the correct parameters, residual diagnostics indicated sharp spikes periodically and so seasonal variation was accounted for as well.

For City 2, the ACF cuts off abruptly, indicating that we have a stationary model. This also implies that our $q$ parameter is 1 from the first spike and $p$ parameter is 3 from the first 3 spikes being past the line.

For City 3, the ACF appears to be following a somewhat sinusodial pattern, indicating some seasonality in our model. Perhaps a first differencing in the seasonal component may remove that pattern from the ACF.

This shows that first differencing was effective, and second differencing is no longer needed.

We test out some ARMA parameters that matches these plots:

```{r, warning = FALSE, message = FALSE, include = FALSE} 
model_1a <- arima(ts_city1, order=c(2,1,1), seasonal=list(order=c(1,0,2), period=48))
model_1b <- arima(ts_city1, order=c(1,1,2), seasonal=list(order=c(1,0,2), period=48))
model_1c <- arima(ts_city1, order=c(2,1,0), seasonal=list(order=c(1,0,2), period=48))

model_2a <- arima(ts_city2, order=c(2,1,1), seasonal=list(order=c(0,0,2), period=48))
model_2b <- arima(ts_city2, order=c(2,1,2), seasonal=list(order=c(0,0,2), period=48))
model_2c <- arima(ts_city2, order=c(2,1,3), seasonal=list(order=c(0,0,2), period=48))

model_3a <- arima(ts_city3, order=c(0,1,0), seasonal=list(order=c(0,1,1), period=48))
model_3b <- arima(ts_city3, order=c(1,1,0), seasonal=list(order=c(1,1,2), period=48))
model_3c <- arima(ts_city3, order=c(1,1,0), seasonal=list(order=c(0,0,2), period=48))
```

We also have our auto.arima models as well to use as reference.

```{r, warning = FALSE, message = FALSE, include = FALSE}
# Fit ARIMA models
fit_city1 <- auto.arima(ts_city1)
fit_city2 <- auto.arima(ts_city2)
fit_city3 <- auto.arima(ts_city3)
```

We determine which the best models are by comparing the AIC values against each other.

```{r, warning = FALSE, message = FALSE, echo = FALSE}
aic_1 <- AIC(fit_city1)
aic_1a <- AIC(model_1a)
aic_1b <- AIC(model_1b)
aic_1c <- AIC(model_1c)

aic_2 <- AIC(fit_city2)
aic_2a <- AIC(model_2a)
aic_2b <- AIC(model_2b)
aic_2c <- AIC(model_2c)

aic_3 <- AIC(fit_city3)
aic_3a <- AIC(model_3a)
aic_3b <- AIC(model_3b)
aic_3c <- AIC(model_3c)

aic_table3 <- data.frame(
  Model = c("Auto.Arima", "SARIMA(2,1,1,1,0,2)", 
            "SARIMA(1,1,2,1,0,2)","SARIMA(2,1,0,1,0,2)"),
    AIC = c(aic_1,aic_1a,aic_1b,aic_1c)
)

# Print the table
kable(aic_table3, col.names = c("Model", "AIC"), 
      caption = "AIC for City 1")

aic_table4 <- data.frame(
  Model = c("Auto.Arima", "SARIMA(0,1,0,0,1,1)", 
            "SARIMA(3,1,2,2,1,2)","SARIMA(2,1,3,2,1,1)"),
    AIC = c(aic_2,aic_2a,aic_2b,aic_2c)
)

# Print the table
kable(aic_table4, col.names = c("Model", "AIC"), 
      caption = "AIC for City 2")

aic_table5 <- data.frame(
  Model = c("Auto.Arima", "SARIMA(2,1,2,2,1,2)", 
            "SARIMA(1,1,0,1,1,2)","SARIMA(1,1,0,0,0,2)"),
    AIC = c(aic_3,aic_3a,aic_3b,aic_3c)
)

# Print the table
kable(aic_table5, col.names = c("Model", "AIC"), 
      caption = "AIC for City 3")
```

For City 1, although the best model with the lowest AIC value is SARIMA(1,1,2,1,0,2). The residual diagnostics doesn't imply stationarity from the Box-Ljung Test:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
tsdiag(model_1b)
```

Instead, we will continue to use the auto.arima model which is the SARIMA(3,0,1,0,0,2) that has p-values for the Box-Ljung Pierce test to be > 0.05. The residuals look randomly spread and the ACF looks stationary for the auto.arima model for City 1.

```{r, warning = FALSE, message = FALSE, echo = FALSE}
tsdiag(fit_city1)
```

For City 2, we pick the model with the lowest AIC value which is SARIMA(2,1,3,2,1,1). They equivalently have the same diagnostics and AIC value as the auto.arima model which was SARIMA(3,1,3,0,0,2). We just picked the other model arbitrarily but either can work.

For both diagnostics, they have p-values for the Box-Ljung Pierce test to be > 0.05. The residuals look randomly spread and the ACF looks stationary.

Below is the diagnostics for the final model on SARIMA(2,1,3,2,1,1)

```{r, warning = FALSE, message = FALSE, echo = FALSE}
tsdiag(model_2c)
```

Below are the diagnostics for the auto.arima model:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
tsdiag(fit_city2)
```

For City 3, the model with the lowest AIC value is SARIMA(1,1,0,1,1,2). This is supported by the Box-Ljung Pierce Test below:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
tsdiag(model_3b)
```
The residuals look randomly spread and the ACF looks stationary.

We want to reconfirm this by checking the residual diagnostics of our final models:

```{r, warning = FALSE, message = FALSE, echo = FALSE}
checkresiduals(fit_city1)
checkresiduals(model_2c)
checkresiduals(model_3b)
```

Confirming this with our residual diagnostics:

- The residuals appear random in all plots
- The ACF's only have spikes that exceed the threshold every 48 lags
- The residual bell-curves are all symmetrically normal.

Now we want to forecast the next 336 points



```{r, warning = FALSE, message = FALSE, include = FALSE}
# Forecast for 336 half-hourly steps ahead (1 week)
forecast_city1 <- forecast(fit_city1, h = 336)
forecast_city2 <- forecast(model_2c, h = 336)
forecast_city3 <- forecast(model_3b, h = 336)

# Extract prediction intervals
pi_city1 <- forecast_city1$pi
pi_city2 <- forecast_city2$pi
pi_city3 <- forecast_city3$pi
```

```{r, warning = FALSE, message = FALSE, echo = FALSE}
# Plot for City 1
plot(forecast_city1, main = "Pollution Forecast for City 1", xlab = "Time", ylab = "Pollutant Concentration")

# Plot for City 2
plot(forecast_city2, main = "Pollution Forecast for City 2", xlab = "Time", ylab = "Pollutant Concentration")

# Plot for City 3
plot(forecast_city3, main = "Pollution Forecast for City 3", xlab = "Time", ylab = "Pollutant Concentration")
```

For all the forecasts, the dark blue portion refers to the 80% prediction interval and the light grey portion refers to the 95% prediction interval.

For City 1, the forecasts look conservative compared to our data, and then it flattens out eventually. This is indicated by our prediction intervals varying somewhat and then flattening out as well. It appears that the best forecasts in the long run is the mean of the series.

For City 2, the forecasts appear to be varying a little bit around the mean, but the prediction intervals slowly get bigger over time, so our forecasts become more uncertain.

For City 3, the forecasts are varying much more sporadically in a sinusodial pattern with much larger prediction intervals that grow quicker over time.

Therefore, we complete the forecasting report. Thank you for reading!


```{r, warning = FALSE, message = FALSE, include = FALSE}
last.name <- "Miranda" # replace with your last name
student.id <- "20818719"  #replace with your student id

city1_out <- as.vector(forecast_city1$mean)
city2_out <- as.vector(forecast_city2$mean)
city3_out <- as.vector(forecast_city3$mean)

matrix_out <- cbind(city1_out,city2_out,city3_out)

###
# Scenario 5 
###
forecast5 <- matrix_out # Forecasts for cities 1-3 should be stored in the columns of a 336x3 dimensional matrix

write.table(forecast5, file = paste("Scenario5_",last.name, student.id,".txt", sep = ""), sep =",", col.names = FALSE, row.names = FALSE )
```














